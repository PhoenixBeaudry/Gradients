#!/usr/bin/env python3
"""
hpo_optuna.py  â€“  1â€‘hour Optuna sweep â†’ full training (multiâ€‘GPU compatible)
--------------------------------------------------------------------------
* Trials log to <WANDB_PROJECT>-hpo and never push to Huggingâ€¯Face.
* eval_loss is extracted (in this order):
    1) wandb-summary.json   2) stdout regex   3) trainer_state.json
"""
from __future__ import annotations
import argparse, copy, json, logging, os, re, shutil, subprocess, tempfile, uuid, time
from pathlib import Path
import yaml, optuna
from datetime import datetime, timedelta
from optuna.pruners import HyperbandPruner
from optuna.storages import RDBStorage    
  

# â”€â”€ logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO,
                    format="%(asctime)s %(levelname)s %(message)s")
LOG = logging.getLogger("hpo_optuna")

MAX_TRIALS_TO_RUN = 30
TRIAL_MAX_STEPS = 400
TRIAL_EVAL_STEPS = 40
TESTING_TRIAL_MAX_STEPS = 50
TESTING_TRIAL_EVAL_STEPS = 25
PERCENT_TIME_FOR_HPO = 0.30
MAX_MINUTES_PER_TRIAL = 30
                   

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hyperâ€‘parameter space â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
def sample_space(trial: optuna.Trial, cfg: dict) -> dict:

    # Model variant params
    if cfg["model_params_count"]:
        model_params_count = cfg["model_params_count"] 
    else:
        model_params_count = 1_000_000_000

    # Scaler based on task type
    if cfg["rl"] == "dpo":
        task_scaler = 0.3
    elif cfg["rl"] == "grpo":
        task_scaler = 0.1
    else:
        task_scaler = 1

    lr_mid   = (3e-5 * (model_params_count / 7e9) ** -0.5)*task_scaler
    lr_low = lr_mid / 4
    lr_high = lr_mid * 2

    # Invariant Params
    params = {
        "optimizer":                      trial.suggest_categorical("optimizer", ["adamw_8bit", "lion_8bit", "adamw_torch"]),
        "adapter":                        trial.suggest_categorical("adapter", ["lora", "None"]),
        "learning_rate":                  trial.suggest_float("learning_rate", lr_low, lr_high, log=True),
        "weight_decay":                   trial.suggest_float("weight_decay", 0.0, 0.1),
    }

    # Always lora for models > 8b
    if model_params_count > 8_000_000_000:
        params |= {
            "adapter":                        trial.suggest_categorical("adapter", ["lora"]),
        }
    else:
        params |= {
            "adapter":                        trial.suggest_categorical("adapter", ["lora", "None"]),
        }

    # DPO Params
    if cfg["rl"] == "dpo":
        params |= {
            "beta":                        trial.suggest_float("beta", 0.01, 0.5, log=True),
            "label_smoothing":             trial.suggest_float("label_smoothing", 0.0, 0.2),
        }

    # GRPO Params
    elif cfg["rl"] == "grpo":
        params |= {
            "beta":                        trial.suggest_float("beta", 0.01, 0.3, log=True),
        }

    # LORA Params
    if params["adapter"] == "lora":
        params |= {
            "lora_r":       trial.suggest_int("lora_r", 16, 1024, step=16),
            "lora_alpha":       trial.suggest_int("lora_alpha", 16, 1024, step=16),
            "lora_dropout":       trial.suggest_float("lora_dropout", 0.0, 0.1),
        }

    return params
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯




# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers for eval_loss extraction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
_EVAL_RE = re.compile(r"eval_loss[^0-9]*([0-9]+\.[0-9]+)")

def loss_from_wandb(out_dir: Path) -> float | None:
    p = out_dir / "wandb" / "latest-run" / "files" / "wandb-summary.json"
    if p.exists():
        with p.open() as f:
            js = json.load(f)
        if "eval_loss" in js:
            return float(js["eval_loss"])
    return None

def loss_from_stdout(stdout: str) -> float | None:
    matches = _EVAL_RE.findall(stdout)
    return float(matches[-1]) if matches else None

def loss_from_state(out_dir: Path) -> float | None:
    p = out_dir / "trainer_state.json"
    if not p.exists():
        return None
    with p.open() as f:
        js = json.load(f)
    for rec in reversed(js.get("log_history", [])):
        if "eval_loss" in rec:
            return float(rec["eval_loss"])
    return None
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Objective (single trial) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
def objective(
    trial: optuna.Trial,
    base_cfg: dict,
    hpo_project: str,
    study_name: str,
    storage_path: str,
    time_when_hpo_finished: datetime,
) -> float:
    cfg = copy.deepcopy(base_cfg)
    trial_params = sample_space(trial, cfg)
    cfg.update(trial_params)

    trial_id = f"trial{trial.number}"
    out_dir = Path(cfg.get("output_root", "./hpo_runs")) / trial_id
    cfg |= {
        "output_dir": str(out_dir),
        "wandb_run": f"{cfg['job_id'][:5]}_{cfg['rl']}_{trial_id}",
        "wandb_project": hpo_project,
        "max_steps": TRIAL_MAX_STEPS,
        "eval_steps": TRIAL_EVAL_STEPS,
        "save_steps": 500,
    }

    if cfg["testing"] == True:
        cfg |= {
            "max_steps": TESTING_TRIAL_MAX_STEPS,
            "eval_steps": TESTING_TRIAL_EVAL_STEPS,
        }

    cfg["hpo_run"] = True
    cfg["required_finish_time"] = (
        datetime.now() + timedelta(minutes=MAX_MINUTES_PER_TRIAL)
    ).isoformat()

    out_dir.mkdir(parents=True, exist_ok=True)

    tmp_cfg = Path(tempfile.mkdtemp()) / f"{trial_id}.yml"
    with tmp_cfg.open("w") as f:
        yaml.safe_dump(cfg, f)

    LOG.info("Starting trial %d with params: %s", trial.number, trial_params)
    # â”€â”€ prepare environment for subprocess â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    env = os.environ.copy()
    env["WANDB_PROJECT"] = hpo_project  # override globally
    env.pop("WANDB_RUN_ID", None)  # avoid carryâ€‘over
    env.pop("WANDB_NAME", None)
    env["OPTUNA_STORAGE"] = storage_path
    env["OPTUNA_STUDY_NAME"] = study_name
    env["OPTUNA_TRIAL_ID"] = str(trial._trial_id)

    if cfg["rl"] == "dpo":
        path_to_train_file = "/workspace/training/train_dpo.py"
    elif cfg["rl"] == "grpo":
        cfg["trl"]["max_completion_length"] = 32
        path_to_train_file = "/workspace/training/train_grpo.py"
    else:
        path_to_train_file = "/workspace/training/train.py"

    cmd = [
        "accelerate", "launch",
        "--use_deepspeed",
        "--zero_stage", "2",
        "--mixed_precision", "bf16",
        path_to_train_file,
        "--config", str(tmp_cfg),
    ]

    # â”€â”€ Run subprocess, capture output after process completes â”€â”€â”€â”€â”€â”€â”€â”€
    stdout = ""
    process_error = None
    try:
        with subprocess.Popen(
            cmd,
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
        ) as cp:
            stdout, _ = cp.communicate()  # No live streaming
            if cp.returncode != 0:
                process_error = subprocess.CalledProcessError(
                    cp.returncode, cmd, output=stdout
                )
    except Exception as e:
        LOG.error(f"Subprocess failed for trial {trial.number}: {e}")
        process_error = e

    # â”€â”€ Error handling (match your original structure) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if process_error:
        msg = str(getattr(process_error, "output", "")) + "\n" + str(process_error)
        if "torch.OutOfMemoryError" in msg:
            LOG.warning("Trial %d failed: OOM error.", trial.number)
            hpo_hours_left = (time_when_hpo_finished - datetime.now()).total_seconds() / 3600
            LOG.info(f"Time remaining for HPO: {hpo_hours_left}h")
            LOG.info("Waiting 3s before starting next trial for cleanup...")
            time.sleep(5)
            return float("-inf") if cfg["rl"] == "grpo" else float("inf")
        elif "optuna.exceptions.TrialPruned" in msg:
            LOG.info("Trial was pruned.")
            hpo_hours_left = (time_when_hpo_finished - datetime.now()).total_seconds() / 3600
            LOG.info(f"Time remaining for HPO: {hpo_hours_left}h")
            time.sleep(5)
            return float("-inf") if cfg["rl"] == "grpo" else float("inf")
        elif "Reached time limit of" in msg:
            LOG.info("Trial ran out of time: attempting to find last loss...")
        else:
            LOG.warning("Trial %d failed:\n%s", trial.number, msg)
            hpo_hours_left = (time_when_hpo_finished - datetime.now()).total_seconds() / 3600
            LOG.info(f"Time remaining for HPO: {hpo_hours_left}h")
            LOG.info("Waiting 3s before starting next trial for cleanup...")
            time.sleep(5)
            return float("-inf") if cfg["rl"] == "grpo" else float("inf")

    # â”€â”€ extract eval_loss (3 fallback methods) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for extractor in (loss_from_wandb, lambda _: loss_from_stdout(stdout), loss_from_state):
        val = extractor(out_dir) if extractor is loss_from_wandb or extractor is loss_from_state else extractor(None)
        if val is not None:
            LOG.info("Trial %d completed â€“ eval_loss: %.4f", trial.number, val)
            shutil.rmtree(tmp_cfg.parent, ignore_errors=True)
            hpo_hours_left = (time_when_hpo_finished - datetime.now()).total_seconds() / 3600
            LOG.info(f"Time remaining for HPO: {hpo_hours_left}h")
            return val

    LOG.warning("eval_loss not found for trial %d â€“ penalising.", trial.number)
    hpo_hours_left = (time_when_hpo_finished - datetime.now()).total_seconds() / 3600
    LOG.info(f"Time remaining for HPO: {hpo_hours_left}h")
    return float("-inf") if cfg["rl"] == "grpo" else float("inf")

# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Run Optuna sweep â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
def run_optuna(base_cfg_path: str) -> dict:
    with open(base_cfg_path) as f:
        base_cfg = yaml.safe_load(f)

    study_name   = base_cfg.get("job_id", "optuna")
    hpo_root     = Path(base_cfg.get("output_root", "./hpo_runs")) / study_name
    hpo_root.mkdir(parents=True, exist_ok=True)
    storage_path = f"sqlite:///{hpo_root / 'hpo.db'}"
    base_project = os.environ.get("WANDB_PROJECT", "Gradients")
    hpo_project  = f"{base_project}-HPO-Trials"

    LOG.info("HPO sweep starting  (project: %s)â€¦", hpo_project)
    storage = RDBStorage(url=storage_path, engine_kwargs={"connect_args": {"timeout": 30}, "pool_pre_ping": True})

    if base_cfg["rl"] == "grpo":
        direction = "maximize"
    else:
        direction = "minimize"

    study = optuna.create_study(direction=direction,
                                study_name=base_cfg["job_id"],
                                load_if_exists=False,
                                storage=storage,
                                pruner=HyperbandPruner(min_resource=3, max_resource=int(TRIAL_MAX_STEPS/TRIAL_EVAL_STEPS), reduction_factor=3))
    
    # calculate how much time we have left for job:
    time_remaining = datetime.fromisoformat(base_cfg['required_finish_time']) - datetime.now()
    seconds_remaining = max(0.0, time_remaining.total_seconds()*PERCENT_TIME_FOR_HPO)
    time_when_hpo_finished = datetime.now() + timedelta(seconds=seconds_remaining)

    LOG.info(f"Time allocated to HPO Search {seconds_remaining/3600}h")
    study.optimize(lambda t: objective(t, base_cfg, hpo_project, study_name, storage_path, time_when_hpo_finished),
                   timeout=int(seconds_remaining),
                   n_trials=MAX_TRIALS_TO_RUN,
                   show_progress_bar=True)

    LOG.info("HPO finished â€“ best eval_loss %.5f with params %s",
            study.best_value, study.best_params)
        
    return study.best_params
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Write optimised YAML & launch main run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
def write_opt_cfg(base_cfg: str, best: dict) -> str:
    with open(base_cfg) as f:
        cfg = yaml.safe_load(f)
    cfg.update(best)
    opt_path = base_cfg.replace(".yml", "_opt.yml")
    with open(opt_path, "w") as f:
        yaml.safe_dump(cfg, f)
    LOG.info("ðŸ’¾  Wrote optimised config â†’ %s", opt_path)
    return opt_path

def launch_training(cfg_path: str):
    with open(cfg_path) as f:
        cfg = yaml.safe_load(f)

    if cfg["rl"] == "dpo":
        path_to_train_file = "/workspace/training/train_dpo.py"
    elif cfg["rl"] == "grpo":
        path_to_train_file = "/workspace/training/train_grpo.py"
    else:
        path_to_train_file = "/workspace/training/train.py"


    cmd = [
        "accelerate", "launch",
        "--use_deepspeed",
        "--zero_stage", "2",
        "--mixed_precision", "bf16",
        path_to_train_file,
        "--config", cfg_path,
    ]

    LOG.info("ðŸš€  Starting full training run")
    subprocess.run(cmd, check=True)
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI entryâ€‘point â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
def main():
    ap = argparse.ArgumentParser(description="HPO then full training")
    ap.add_argument("--config",          required=True, help="Base YAML config file")
    args = ap.parse_args()
    with open(args.config) as f:
        base_cfg = yaml.safe_load(f)
        
    if base_cfg["do_hpo"] == False:
        launch_training(args.config)
        return
    
    best_params   = run_optuna(args.config)
    optimised_cfg = write_opt_cfg(args.config, best_params)
    time.sleep(10)
    launch_training(optimised_cfg)

if __name__ == "__main__":
    main()
